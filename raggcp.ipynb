{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PATH'] += ':/Users/abderrazzak/google-cloud-sdk/bin'\n",
    "\n",
    "os.environ['REGION'] = \"us-central1\"\n",
    "os.environ['PROJECT_ID'] = \"orangebot-7551\"\n",
    "os.environ['BUCKET_URI'] = 'gs://orange_maroc'\n",
    "\n",
    "REGION = os.environ['REGION']\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "BUCKET_URI = os.environ['BUCKET_URI']\n",
    "\n",
    "# The number of dimensions for the textembedding-gecko@003 is 768\n",
    "# If other embedder is used, the dimensions would probably need to change.\n",
    "DIMENSIONS = 768\n",
    "\n",
    "# Index Constants\n",
    "DISPLAY_NAME = \"orange_maroc\"\n",
    "DEPLOYED_INDEX_ID = \"orange_maroc_endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:Creating gs://orange_maroc/...\n"
     ]
    }
   ],
   "source": [
    "password = \"\"  # Replace with your actual password\n",
    "command = f\"echo {password} | sudo -S gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}\"\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from langchain_google_vertexai import VertexAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721033030.501282    8819 work_stealing_thread_pool.cc:321] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1721033030.964322    8819 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721033032.163356   27142 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "embedding_model = VertexAIEmbeddings(model_name=\"textembedding-gecko@003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720787370.318694  707106 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/662868193247/locations/us-central1/indexes/1270309764034723840/operations/2310908218764689408\n",
      "MatchingEngineIndex created. Resource name: projects/662868193247/locations/us-central1/indexes/1270309764034723840\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/662868193247/locations/us-central1/indexes/1270309764034723840')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720787391.894778  707106 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1720787392.688504  709600 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720787635.530659  709592 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "# NOTE : This operation can take upto 30 seconds\n",
    "my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=150,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    index_update_method=\"STREAM_UPDATE\",  # allowed values BATCH_UPDATE , STREAM_UPDATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720787691.902041  707106 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/662868193247/locations/us-central1/indexEndpoints/7001984714793811968/operations/8686319739795931136\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/662868193247/locations/us-central1/indexEndpoints/7001984714793811968\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/662868193247/locations/us-central1/indexEndpoints/7001984714793811968')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720787694.020746  707106 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1720787694.725809  709594 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720787694.731568  707106 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1720787694.733464  709597 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "# Create an endpoint\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=f\"{DISPLAY_NAME}-endpoint\", public_endpoint_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/662868193247/locations/us-central1/indexEndpoints/7001984714793811968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720787837.578296  707106 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/662868193247/locations/us-central1/indexEndpoints/7001984714793811968/operations/5313123618895429632\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/662868193247/locations/us-central1/indexEndpoints/7001984714793811968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720789429.038822  707106 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1720789429.878749  709600 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: \"orange_maroc_endpoint\"\n",
       "index: \"projects/662868193247/locations/us-central1/indexes/1270309764034723840\"\n",
       "create_time {\n",
       "  seconds: 1720787838\n",
       "  nanos: 358217000\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1720789424\n",
       "  nanos: 649213000\n",
       "}\n",
       "automatic_resources {\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720789672.387593  709980 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "# NOTE : This operation can take upto 20 minutes\n",
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"orange_maroc_endpoint\"\n",
       "index: \"projects/662868193247/locations/us-central1/indexes/1270309764034723840\"\n",
       "create_time {\n",
       "  seconds: 1720787838\n",
       "  nanos: 358217000\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1720789424\n",
       "  nanos: 649213000\n",
       "}\n",
       "automatic_resources {\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import (\n",
    "    VectorSearchVectorStore,\n",
    "    VectorSearchVectorStoreDatastore,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text with metadata\n",
    "record_data = [\n",
    "    {\n",
    "        \"description\": \"A versatile pair of dark-wash denim jeans.\"\n",
    "        \"Made from durable cotton with a classic straight-leg cut, these jeans\"\n",
    "        \" transition easily from casual days to dressier occasions.\",\n",
    "        \"price\": 65.00,\n",
    "        \"color\": \"blue\",\n",
    "        \"season\": [\"fall\", \"winter\", \"spring\"],\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"A lightweight linen button-down shirt in a crisp white.\"\n",
    "        \" Perfect for keeping cool with breathable fabric and a relaxed fit.\",\n",
    "        \"price\": 34.99,\n",
    "        \"color\": \"white\",\n",
    "        \"season\": [\"summer\", \"spring\"],\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"A soft, chunky knit sweater in a vibrant forest green. \"\n",
    "        \"The oversized fit and cozy wool blend make this ideal for staying warm \"\n",
    "        \"when the temperature drops.\",\n",
    "        \"price\": 89.99,\n",
    "        \"color\": \"green\",\n",
    "        \"season\": [\"fall\", \"winter\"],\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"A classic crewneck t-shirt in a soft, heathered blue. \"\n",
    "        \"Made from comfortable cotton jersey, this t-shirt is a wardrobe essential \"\n",
    "        \"that works for every season.\",\n",
    "        \"price\": 19.99,\n",
    "        \"color\": \"blue\",\n",
    "        \"season\": [\"fall\", \"winter\", \"summer\", \"spring\"],\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"A flowing midi-skirt in a delicate floral print. \"\n",
    "        \"Lightweight and airy, this skirt adds a touch of feminine style \"\n",
    "        \"to warmer days.\",\n",
    "        \"price\": 45.00,\n",
    "        \"color\": \"white\",\n",
    "        \"season\": [\"spring\", \"summer\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Parse and prepare input data\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "for record in record_data:\n",
    "    record = record.copy()\n",
    "    page_content = record.pop(\"description\")\n",
    "    texts.append(page_content)\n",
    "    if isinstance(page_content, str):\n",
    "        metadata = {**record}\n",
    "        metadatas.append(metadata)\n",
    "\n",
    "datastore_client_kwargs = {\n",
    "    'database': '(default)',\n",
    "    # add other necessary parameters here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and prepare input data\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "for record in record_data:\n",
    "    record = record.copy()\n",
    "    page_content = record.pop(\"description\")\n",
    "    texts.append(page_content)\n",
    "    if isinstance(page_content, str):\n",
    "        metadata = {**record}\n",
    "        metadatas.append(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_client_kwargs = {\n",
    "    'database': '(default)',\n",
    "    # add other necessary parameters here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720981422.517447   31107 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1720981422.826684  269258 subchannel.cc:806] subchannel 0x12b8fe020 {address=ipv6:%5B2a00:1450:4006:806::200a%5D:443, args={grpc.client_channel_factory=0x11dab2880, grpc.default_authority=europe-west4-aiplatform.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x12bb32830, grpc.internal.client_channel_call_destination=0x1187cb598, grpc.internal.event_engine=0x12b8b8c20, grpc.internal.security_connector=0x12b88c5d0, grpc.internal.subchannel_pool=0x108b8aaf0, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.0, grpc.resource_quota=0x11dab1ed0, grpc.server_uri=dns:///europe-west4-aiplatform.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-07-14T19:23:42.826495+01:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1720981422.866548  269250 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720981423.570632  269256 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720981423.572922   31107 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1720981428.900036  269255 subchannel.cc:806] subchannel 0x11dafefa0 {address=ipv6:%5B2a00:1450:4006:800::200a%5D:443, args={grpc.client_channel_factory=0x11dab2880, grpc.default_authority=europe-west4-aiplatform.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x12b8c7b70, grpc.internal.client_channel_call_destination=0x1187cb598, grpc.internal.event_engine=0x11dafef40, grpc.internal.security_connector=0x11da96130, grpc.internal.subchannel_pool=0x108b8aaf0, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.0, grpc.resource_quota=0x11dab1ed0, grpc.server_uri=dns:///europe-west4-aiplatform.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-07-14T19:23:48.8998+01:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1720981429.082821  269259 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720981429.359632  269257 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720981429.361284   31107 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1720981429.366711   31107 work_stealing_thread_pool.cc:321] WorkStealingThreadPoolImpl::PrepareFork\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720981479.717983  271022 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "vector_store = VectorSearchVectorStoreDatastore.from_components(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    "    index_id=\"502362464684343296\",\n",
    "    endpoint_id=\"6559915069730193408\",\n",
    "    embedding=embedding_model,\n",
    "    datastore_client_kwargs=datastore_client_kwargs,\n",
    "    stream_update=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720982041.820806  270947 subchannel.cc:806] subchannel 0x12b8fcc70 {address=ipv6:%5B2a00:1450:4006:803::200a%5D:443, args={grpc.client_channel_factory=0x11dab2880, grpc.default_authority=datastore.googleapis.com:443, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x119813050, grpc.internal.client_channel_call_destination=0x1187cb598, grpc.internal.event_engine=0x12b892390, grpc.internal.security_connector=0x12b8c1080, grpc.internal.subchannel_pool=0x108b8aaf0, grpc.primary_user_agent=gcloud-python/2.4.1 grpc-python/1.65.0, grpc.resource_quota=0x11dab1ed0, grpc.server_uri=dns:///datastore.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-07-14T19:34:01.818588+01:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1720982043.308557  280621 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1720982043.313254  280621 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1720982043.732923  270949 subchannel.cc:806] subchannel 0x11fcd7b30 {address=ipv6:%5B2a00:1450:4006:805::200a%5D:443, args={grpc.client_channel_factory=0x11dab2880, grpc.default_authority=us-central1-aiplatform.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x12b89d5c0, grpc.internal.client_channel_call_destination=0x1187cb598, grpc.internal.event_engine=0x11fced510, grpc.internal.security_connector=0x11fced450, grpc.internal.subchannel_pool=0x108b8aaf0, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.0, grpc.resource_quota=0x11dab1ed0, grpc.server_uri=dns:///us-central1-aiplatform.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-07-14T19:34:03.732652+01:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1720982043.986309  270951 subchannel.cc:806] subchannel 0x11fcedd30 {address=ipv6:%5B2a00:1450:4006:813::200a%5D:443, args={grpc.client_channel_factory=0x11dab2880, grpc.default_authority=us-central1-aiplatform.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x12b89d5c0, grpc.internal.client_channel_call_destination=0x1187cb598, grpc.internal.event_engine=0x11fc96b90, grpc.internal.security_connector=0x11fcfeba0, grpc.internal.subchannel_pool=0x108b8aaf0, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.0, grpc.resource_quota=0x11dab1ed0, grpc.server_uri=dns:///us-central1-aiplatform.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-07-14T19:34:03.986113+01:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1720982044.242485  270948 subchannel.cc:806] subchannel 0x11fcb6ba0 {address=ipv6:%5B2a00:1450:4006:802::200a%5D:443, args={grpc.client_channel_factory=0x11dab2880, grpc.default_authority=us-central1-aiplatform.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x12b89d5c0, grpc.internal.client_channel_call_destination=0x1187cb598, grpc.internal.event_engine=0x11fcb5800, grpc.internal.security_connector=0x11fcb65e0, grpc.internal.subchannel_pool=0x108b8aaf0, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.0, grpc.resource_quota=0x11dab1ed0, grpc.server_uri=dns:///us-central1-aiplatform.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-07-14T19:34:04.242294+01:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1720982044.495992  270946 subchannel.cc:806] subchannel 0x11fcec550 {address=ipv6:%5B2a00:1450:4006:812::200a%5D:443, args={grpc.client_channel_factory=0x11dab2880, grpc.default_authority=us-central1-aiplatform.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x12b89d5c0, grpc.internal.client_channel_call_destination=0x1187cb598, grpc.internal.event_engine=0x11fcb68b0, grpc.internal.security_connector=0x11fcf6340, grpc.internal.subchannel_pool=0x108b8aaf0, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.0, grpc.resource_quota=0x11dab1ed0, grpc.server_uri=dns:///us-central1-aiplatform.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-07-14T19:34:04.495921+01:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1720982044.736061  270951 subchannel.cc:761] subchannel 0x11fcd7b30 {address=ipv6:%5B2a00:1450:4006:805::200a%5D:443, args={grpc.client_channel_factory=0x11dab2880, grpc.default_authority=us-central1-aiplatform.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x12b89d5c0, grpc.internal.client_channel_call_destination=0x1187cb598, grpc.internal.event_engine=0x11fced510, grpc.internal.security_connector=0x11fced450, grpc.internal.subchannel_pool=0x108b8aaf0, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.0, grpc.resource_quota=0x11dab1ed0, grpc.server_uri=dns:///us-central1-aiplatform.googleapis.com:443}}: backoff delay elapsed, reporting IDLE\n",
      "I0000 00:00:1720982044.774560  270946 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720982044.775541  270949 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720982045.092709  280621 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720982045.091926  270943 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720982045.093599  280621 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting datapoints MatchingEngineIndex index: projects/662868193247/locations/europe-west4/indexes/502362464684343296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:Upserting datapoints MatchingEngineIndex index: projects/662868193247/locations/europe-west4/indexes/502362464684343296\n",
      "I0000 00:00:1720982051.523019   31107 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1720982051.962361  270951 subchannel.cc:806] subchannel 0x11a665be0 {address=ipv6:%5B2a00:1450:4006:811::200a%5D:443, args={grpc.client_channel_factory=0x11dab2880, grpc.default_authority=europe-west4-aiplatform.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x11a6817b0, grpc.internal.client_channel_call_destination=0x1187cb598, grpc.internal.event_engine=0x108d93e90, grpc.internal.security_connector=0x11a697360, grpc.internal.subchannel_pool=0x108b8aaf0, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.0, grpc.resource_quota=0x11dab1ed0, grpc.server_uri=dns:///europe-west4-aiplatform.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-07-14T19:34:11.96217+01:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1720982052.146832  270949 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchingEngineIndex index Upserted datapoints. Resource name: projects/662868193247/locations/europe-west4/indexes/502362464684343296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720982052.705164  270951 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:MatchingEngineIndex index Upserted datapoints. Resource name: projects/662868193247/locations/europe-west4/indexes/502362464684343296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e8cc98c8-58fe-4076-9875-b9183b002e9f',\n",
       " '831a2c58-244a-4810-88ab-9e8110f83304',\n",
       " 'f686949e-66bc-4a11-88b2-eb0ae5630fff',\n",
       " '835df3a9-021c-4f89-aad0-81d01416d530',\n",
       " '73d6be74-6346-415f-ad0f-c99754b7b53c']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_texts(texts=texts, metadatas=metadatas, is_complete_overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import (\n",
    "    Namespace,\n",
    "    NumericNamespace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VectorSearchVectorStoreDatastore' object has no attribute 'get_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorSearchVectorStoreDatastore' object has no attribute 'get_index'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'season': ['summer', 'spring'], 'color': 'white', 'price': 34.99}, page_content='A lightweight linen button-down shirt in a crisp white. Perfect for keeping cool with breathable fabric and a relaxed fit.'),\n",
       " Document(metadata={'season': ['fall', 'winter', 'summer', 'spring'], 'color': 'blue', 'price': 19.99}, page_content='A classic crewneck t-shirt in a soft, heathered blue. Made from comfortable cotton jersey, this t-shirt is a wardrobe essential that works for every season.'),\n",
       " Document(metadata={'season': ['spring', 'summer'], 'color': 'white', 'price': 45.0}, page_content='A flowing midi-skirt in a delicate floral print. Lightweight and airy, this skirt adds a touch of feminine style to warmer days.'),\n",
       " Document(metadata={'season': ['fall', 'winter', 'spring'], 'color': 'blue', 'price': 65.0}, page_content='A versatile pair of dark-wash denim jeans.Made from durable cotton with a classic straight-leg cut, these jeans transition easily from casual days to dressier occasions.'),\n",
       " Document(metadata={'season': ['fall', 'winter'], 'color': 'green', 'price': 89.99}, page_content='A soft, chunky knit sweater in a vibrant forest green. The oversized fit and cozy wool blend make this ideal for staying warm when the temperature drops.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720798793.749594  871447 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "# Try running a simple similarity search\n",
    "\n",
    "# Below code should return 5 results\n",
    "vector_store.similarity_search(\"shirt\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'season': ['summer', 'spring'], 'color': 'white', 'price': 34.99}, page_content='A lightweight linen button-down shirt in a crisp white. Perfect for keeping cool with breathable fabric and a relaxed fit.'),\n",
       " Document(metadata={'season': ['fall', 'winter', 'summer', 'spring'], 'color': 'blue', 'price': 19.99}, page_content='A classic crewneck t-shirt in a soft, heathered blue. Made from comfortable cotton jersey, this t-shirt is a wardrobe essential that works for every season.')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720799093.941880  871603 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720799093.946460  871603 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720799464.309203  871447 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "# Try running a similarity search with combination of text and numeric filter\n",
    "filters = [Namespace(name=\"season\", allow_tokens=[\"spring\"])]\n",
    "numeric_filters = [NumericNamespace(name=\"price\", value_float=40.0, op=\"LESS\")]\n",
    "\n",
    "# Below code should return 2 results now\n",
    "vector_store.similarity_search(\n",
    "    \"shirt\", k=5, filter=filters, numeric_filter=numeric_filters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectore_store as retriever\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'season': ['summer', 'spring'], 'color': 'white', 'price': 34.99}, page_content='A lightweight linen button-down shirt in a crisp white. Perfect for keeping cool with breathable fabric and a relaxed fit.'),\n",
       " Document(metadata={'season': ['fall', 'winter'], 'color': 'green', 'price': 89.99}, page_content='A soft, chunky knit sweater in a vibrant forest green. The oversized fit and cozy wool blend make this ideal for staying warm when the temperature drops.'),\n",
       " Document(metadata={'season': ['fall', 'winter', 'summer', 'spring'], 'color': 'blue', 'price': 19.99}, page_content='A classic crewneck t-shirt in a soft, heathered blue. Made from comfortable cotton jersey, this t-shirt is a wardrobe essential that works for every season.'),\n",
       " Document(metadata={'season': ['spring', 'summer'], 'color': 'white', 'price': 45.0}, page_content='A flowing midi-skirt in a delicate floral print. Lightweight and airy, this skirt adds a touch of feminine style to warmer days.')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform simple similarity search on retriever\n",
    "retriever.invoke(\"What are my options in breathable fabric?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "llm = VertexAI(model_name=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abderrazzak/Desktop/rag_gcp/raggcp/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "I0000 00:00:1720799680.839160  707106 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have two options in breathable fabric: the lightweight linen button-down shirt and the classic crewneck t-shirt. \n",
      " \n",
      " * The linen button-down shirt is made from crisp white linen, which is known for being a breathable and lightweight fabric. \n",
      " * The classic crewneck t-shirt is made from soft, heathered blue cotton jersey, which is also a breathable and comfortable fabric. \n",
      " \n",
      " Both of these shirts would be a good choice for staying cool in warm weather. The linen shirt is a bit more dressy than the t-shirt, so it might be a better choice if you are going to be somewhere where you need to look a little more put together. The t-shirt is more casual, so it would be a good choice for everyday wear.\n",
      "REFERENCES\n",
      "[Document(metadata={'season': ['summer', 'spring'], 'color': 'white', 'price': 34.99}, page_content='A lightweight linen button-down shirt in a crisp white. Perfect for keeping cool with breathable fabric and a relaxed fit.'), Document(metadata={'season': ['fall', 'winter', 'summer', 'spring'], 'color': 'blue', 'price': 19.99}, page_content='A classic crewneck t-shirt in a soft, heathered blue. Made from comfortable cotton jersey, this t-shirt is a wardrobe essential that works for every season.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720799924.665824  871447 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720799924.666682  871447 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720799924.667270  871447 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720800294.946795  871447 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "filters = [Namespace(name=\"season\", allow_tokens=[\"spring\"])]\n",
    "numeric_filters = [NumericNamespace(name=\"price\", value_float=40.0, op=\"LESS\")]\n",
    "\n",
    "retriever.search_kwargs = {\"k\": 2, \"filter\": filters, \"numeric_filter\": numeric_filters}\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "question = \"What are my options in breathable fabric?\"\n",
    "response = retrieval_qa({\"query\": question})\n",
    "print(f\"{response['result']}\")\n",
    "print(\"REFERENCES\")\n",
    "print(f\"{response['source_documents']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT = f\"projects/{PROJECT_ID}/locations/{REGION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform_v1 as aipv1\n",
    "from google.api_core.client_options import ClientOptions\n",
    "\n",
    "ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720800590.808494  707106 work_stealing_thread_pool.cc:321] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1720800591.284697  707106 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "index_client = aipv1.IndexServiceClient(\n",
    "            client_options=ClientOptions(api_endpoint=ENDPOINT)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_result = index_client.list_indexes(\n",
    "            request=aipv1.ListIndexesRequest(parent=PARENT)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [\n",
    "            response.name\n",
    "            for response in page_result\n",
    "            if response.display_name == DISPLAY_NAME\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['projects/662868193247/locations/us-central1/indexes/1270309764034723840']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720800840.276845  903962 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.cloud import aiplatform\n",
    "from langchain_google_vertexai import (\n",
    "   VectorSearchVectorStoreDatastore\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "from rag.logger import logger\n",
    "\n",
    "\n",
    "from google.cloud import aiplatform_v1 as aipv1\n",
    "from google.api_core.client_options import ClientOptions\n",
    "\n",
    "\n",
    "class VertexAIVectorStore:\n",
    "    def __init__(self, project_id: str,\n",
    "                 region: str,\n",
    "                 index_name: str,\n",
    "                 index_endpoint_name: Optional[str] = None,\n",
    "                 dimensions: int = 768 \n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the Raggcp class.\n",
    "\n",
    "        Args:\n",
    "            project_id (str): The ID of the Google Cloud project.\n",
    "            region (str): The region where the index and index endpoint will be created.\n",
    "            index_name (str): The name of the index.\n",
    "            index_endpoint_name (Optional[str], optional): The name of the index endpoint. If not provided, it will be set to \"{index_name}_endpoint\". Defaults to None.\n",
    "            dimensions (int, optional): The number of dimensions for the index. Defaults to 768.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.project_id = project_id\n",
    "        self.region = region\n",
    "        self.dimensions = dimensions\n",
    "        self.index_name = index_name\n",
    "        self.index_endpoint_name = index_endpoint_name or f\"{self.index_name}_endpoint\"\n",
    "        self.PARENT = f\"projects/{self.project_id}/locations/{self.region}\"\n",
    "\n",
    "        ENDPOINT = f\"{self.region}-aiplatform.googleapis.com\"\n",
    "\n",
    "        # set index client\n",
    "        self.index_client = aipv1.IndexServiceClient(\n",
    "            client_options=ClientOptions(api_endpoint=ENDPOINT)\n",
    "        )\n",
    "        # set index endpoint client\n",
    "        self.index_endpoint_client = aipv1.IndexEndpointServiceClient(\n",
    "            client_options=ClientOptions(api_endpoint=ENDPOINT)\n",
    "        )\n",
    "\n",
    "    def get_index(self):\n",
    "        \"\"\"\n",
    "        Retrieves the index with the specified name.\n",
    "\n",
    "        Returns:\n",
    "            The index with the specified name, or None if it doesn't exist.\n",
    "            :rtype: google.cloud.aiplatform_v1.types.index.Index or None\n",
    "        \"\"\"\n",
    "        # Check if index exists\n",
    "        page_result = self.index_client.list_indexes(\n",
    "            request=aipv1.ListIndexesRequest(parent=self.PARENT)\n",
    "        )\n",
    "        indexes = [\n",
    "            response.name\n",
    "            for response in page_result\n",
    "            if response.display_name == self.index_name\n",
    "        ]\n",
    "\n",
    "        if len(indexes) == 0:\n",
    "            return None\n",
    "\n",
    "        index_id = indexes[0]\n",
    "        return self.index_client.get_index(request=aipv1.GetIndexRequest(name=index_id))\n",
    "    \n",
    "    def get_index_endpoint(self):\n",
    "        \"\"\"\n",
    "        Retrieves the index endpoint with the specified name.\n",
    "\n",
    "        Returns:\n",
    "            The index endpoint object if found, None otherwise.\n",
    "            :rtype: google.cloud.aiplatform_v1.types.index.IndexEndpoint or None\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check if index endpoint exists\n",
    "        page_result = self.index_endpoint_client.list_index_endpoints(\n",
    "            request=aipv1.ListIndexEndpointsRequest(parent=self.PARENT)\n",
    "        )\n",
    "        index_endpoints = [\n",
    "            response.name\n",
    "            for response in page_result\n",
    "            if response.display_name == self.index_endpoint_name\n",
    "        ]\n",
    "\n",
    "        if len(index_endpoints) == 0:\n",
    "            return None\n",
    "\n",
    "        index_endpoint_id = index_endpoints[0]\n",
    "        return self.index_endpoint_client.get_index_endpoint(\n",
    "            request=aipv1.GetIndexEndpointRequest(name=index_endpoint_id)\n",
    "        )\n",
    "\n",
    "    def delete_index(self):\n",
    "        \"\"\"\n",
    "        Deletes the matching engine index.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if index exists\n",
    "        index = self.get_index()\n",
    "\n",
    "        # create index if does not exists\n",
    "        if index:\n",
    "            # Delete index\n",
    "            index_id = index.name\n",
    "            logger.info(f\"Deleting Index {self.index_name} with id {index_id}\")\n",
    "            self.index_client.delete_index(name=index_id)\n",
    "        else:\n",
    "            raise Exception(\"Index {index_name} does not exists.\")\n",
    "\n",
    "    def delete_index_endpoint(self):\n",
    "        \"\"\"\n",
    "        Deletes the matching engine index endpoint.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if index endpoint exists\n",
    "        index_endpoint = self.get_index_endpoint()\n",
    "\n",
    "        # Create Index Endpoint if does not exists\n",
    "        if index_endpoint:\n",
    "            logger.info(\n",
    "                f\"Index endpoint {self.index_endpoint_name}  exists with resource \"\n",
    "                + f\"name as {index_endpoint.name} and endpoint domain name as \"\n",
    "                + f\"{index_endpoint.public_endpoint_domain_name}\"\n",
    "            )\n",
    "\n",
    "            index_endpoint_id = index_endpoint.name\n",
    "            index_endpoint = self.index_endpoint_client.get_index_endpoint(\n",
    "                name=index_endpoint_id\n",
    "            )\n",
    "            # Undeploy existing indexes\n",
    "            for d_index in index_endpoint.deployed_indexes:\n",
    "                logger.info(\n",
    "                    f\"Undeploying index with id {d_index.id} from Index endpoint {self.index_endpoint_name}\"\n",
    "                )\n",
    "                request = aipv1.UndeployIndexRequest(\n",
    "                    index_endpoint=index_endpoint_id, deployed_index_id=d_index.id\n",
    "                )\n",
    "                r = self.index_endpoint_client.undeploy_index(request=request)\n",
    "                response = r.result()\n",
    "                logger.info(response)\n",
    "\n",
    "            # Delete index endpoint\n",
    "            logger.info(\n",
    "                f\"Deleting Index endpoint {self.index_endpoint_name} with id {index_endpoint_id}\"\n",
    "            )\n",
    "            self.index_endpoint_client.delete_index_endpoint(name=index_endpoint_id)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Index endpoint {self.index_endpoint_name} does not exists.\"\n",
    "            )\n",
    "        \n",
    "    def delete_all(self):\n",
    "        \"\"\"\n",
    "        Deletes the matching engine index and endpoint.\n",
    "        \"\"\"\n",
    "        self.delete_index_endpoint()\n",
    "        self.delete_index()\n",
    "\n",
    "    def create_index(self):\n",
    "        \"\"\"\n",
    "        Creates a matching engine index with the specified parameters.\n",
    "\n",
    "        Returns:\n",
    "            The created matching engine index.\n",
    "            :rtype: google.cloud.aiplatform.matching_engine.matching_engine_index.MatchingEngineIndex\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Get index\n",
    "        index = self.get_index()\n",
    "        # Create index if does not exists\n",
    "        if index:\n",
    "            logger.info(f\"Index {self.index_name} already exists with id {index.name}\")\n",
    "            return aiplatform.MatchingEngineIndex(index_name=index.name)\n",
    "        \n",
    "        logger.info(f\"Index {self.index_name} does not exists. Creating index ...\")\n",
    "        index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "            display_name=self.index_name,\n",
    "            location=self.region,\n",
    "            dimensions=self.dimensions,\n",
    "            approximate_neighbors_count=150,\n",
    "            distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "            index_update_method=\"STREAM_UPDATE\",  # allowed values BATCH_UPDATE , STREAM_UPDATE\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Index created: {index.display_name}\")\n",
    "        return index\n",
    "\n",
    "    def create_endpoint(self):\n",
    "        \"\"\"\n",
    "        Creates an endpoint for the matching engine index.\n",
    "\n",
    "        Returns:\n",
    "            The created index endpoint.\n",
    "            :rtype: google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint\n",
    "        \"\"\"\n",
    "\n",
    "        # Get index endpoint if exists\n",
    "        index_endpoint = self.get_index_endpoint()\n",
    "        # Create Index Endpoint if does not exists\n",
    "        if index_endpoint:\n",
    "            logger.info(\n",
    "                f\"Index endpoint {self.index_endpoint_name} already exists with resource \"\n",
    "                + f\"name as {index_endpoint.name} and endpoint domain name as \"\n",
    "                + f\"{index_endpoint.public_endpoint_domain_name}\"\n",
    "            )\n",
    "            return aiplatform.MatchingEngineIndexEndpoint(index_endpoint_name=index_endpoint.name)\n",
    "        \n",
    "        logger.info(\n",
    "            f\"Index endpoint {self.index_endpoint_name} does not exists. Creating index endpoint...\"\n",
    "        )\n",
    "        # Create an endpoint\n",
    "        index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "            display_name=self.index_endpoint_name, \n",
    "            location=self.region,\n",
    "            public_endpoint_enabled=True\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Endpoint created: {index_endpoint.display_name}\")\n",
    "        return index_endpoint\n",
    "\n",
    "    def deploy(self):\n",
    "        # NOTE : This operation can take upto 20 minutes\n",
    "        \"\"\"\n",
    "        Deploys the index to the endpoint.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Deploy index to endpoint\n",
    "        index = self.create_index()\n",
    "        index_endpoint = self.create_endpoint()\n",
    "        deployed_index_id = index_endpoint.display_name\n",
    "\n",
    "        index_endpoint = index_endpoint.deploy_index(\n",
    "            index=index, \n",
    "            deployed_index_id=deployed_index_id\n",
    "        )\n",
    "        logger.info(f\"Index deployed to endpoint: {index_endpoint.display_name}\")\n",
    "        logger.info(f\"Deployed indexes: {index_endpoint.deployed_indexes}\")\n",
    "\n",
    "    def get_vector_store(self, embedding_model, datastore_client_kwargs):\n",
    "        # https://python.langchain.com/v0.2/docs/integrations/retrievers/google_vertex_ai_search/\n",
    "\n",
    "        # add filters\n",
    "        # https://github.com/langchain-ai/langchain/issues/5073\n",
    "\n",
    "        \"\"\"\n",
    "            Parameters:\n",
    "            - embedding_model: The embedding model used for vectorization.\n",
    "            - datastore_client_kwargs: The datastore client kwargs.\n",
    "\n",
    "            Returns:\n",
    "            - vector_store: The vector store object for the matching engine index.\n",
    "        \"\"\"\n",
    "\n",
    "        vector_store = VectorSearchVectorStoreDatastore.from_components(\n",
    "            project_id=self.project_id,\n",
    "            region=self.region,\n",
    "            index_id=self.get_index().name,\n",
    "            endpoint_id=self.get_index_endpoint().name,\n",
    "            embedding=embedding_model,\n",
    "            datastore_client_kwargs=datastore_client_kwargs,\n",
    "            stream_update=True,\n",
    "        )\n",
    "        return vector_store\n",
    "\n",
    "    def upsert(self, texts, metadatas, embedding_model, datastore_client_kwargs):\n",
    "        # create datastore first \n",
    "        \"\"\"\n",
    "        Upserts the given texts and metadatas into the specified index.\n",
    "\n",
    "        Parameters:\n",
    "        - texts (list): A list of texts to be upserted.\n",
    "        - metadatas (list): A list of metadata associated with each text.\n",
    "        - index_endpoint (IndexEndpoint): The index endpoint to upsert the data into.\n",
    "        - index (Index): The index to upsert the data into.\n",
    "        - embedding_model: The embedding model used for vectorization.\n",
    "        - datastore_client_kwargs: The datastore client kwargs.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        \n",
    "        vector_store = self.get_vector_store(embedding_model, datastore_client_kwargs)\n",
    "        vector_store.add_texts(texts=texts, metadatas=metadatas, is_complete_overwrite=True)\n",
    "        logger.info(\"Upserted data to the index.\")\n",
    "\n",
    "    def retrieve(self, embedding_model, datastore_client_kwargs):\n",
    "        \"\"\"\n",
    "        Retrieves the vector store using the specified embedding model and datastore client arguments.\n",
    "\n",
    "        Parameters:\n",
    "        - embedding_model: The embedding model to use for retrieval.\n",
    "        - datastore_client_kwargs: The keyword arguments to pass to the datastore client.\n",
    "\n",
    "        Returns:\n",
    "        - retriever: The retriever object for the vector store.\n",
    "        \"\"\"\n",
    "        vector_store = self.get_vector_store(embedding_model, datastore_client_kwargs)\n",
    "        return vector_store.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text with metadata\n",
    "record_data = [\n",
    "    {\n",
    "        \"description\": \"A versatile pair of dark-wash denim jeans.\"\n",
    "        \"Made from durable cotton with a classic straight-leg cut, these jeans\"\n",
    "        \" transition easily from casual days to dressier occasions.\",\n",
    "        \"price\": 65.00,\n",
    "        \"color\": \"blue\",\n",
    "        \"season\": [\"fall\", \"winter\", \"spring\"],\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"A lightweight linen button-down shirt in a crisp white.\"\n",
    "        \" Perfect for keeping cool with breathable fabric and a relaxed fit.\",\n",
    "        \"price\": 34.99,\n",
    "        \"color\": \"white\",\n",
    "        \"season\": [\"summer\", \"spring\"],\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"A soft, chunky knit sweater in a vibrant forest green. \"\n",
    "        \"The oversized fit and cozy wool blend make this ideal for staying warm \"\n",
    "        \"when the temperature drops.\",\n",
    "        \"price\": 89.99,\n",
    "        \"color\": \"green\",\n",
    "        \"season\": [\"fall\", \"winter\"],\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"A classic crewneck t-shirt in a soft, heathered blue. \"\n",
    "        \"Made from comfortable cotton jersey, this t-shirt is a wardrobe essential \"\n",
    "        \"that works for every season.\",\n",
    "        \"price\": 19.99,\n",
    "        \"color\": \"blue\",\n",
    "        \"season\": [\"fall\", \"winter\", \"summer\", \"spring\"],\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"A flowing midi-skirt in a delicate floral print. \"\n",
    "        \"Lightweight and airy, this skirt adds a touch of feminine style \"\n",
    "        \"to warmer days.\",\n",
    "        \"price\": 45.00,\n",
    "        \"color\": \"white\",\n",
    "        \"season\": [\"spring\", \"summer\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Parse and prepare input data\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "for record in record_data:\n",
    "    record = record.copy()\n",
    "    page_content = record.pop(\"description\")\n",
    "    texts.append(page_content)\n",
    "    if isinstance(page_content, str):\n",
    "        metadata = {**record}\n",
    "        metadatas.append(metadata)\n",
    "\n",
    "datastore_client_kwargs = {\n",
    "    'database': 'orangeds',\n",
    "    # add other necessary parameters here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PATH'] += ':/Users/abderrazzak/google-cloud-sdk/bin'\n",
    "\n",
    "os.environ['REGION'] = \"europe-west4\"\n",
    "os.environ['PROJECT_ID'] = \"orangebot-7551\"\n",
    "os.environ['BUCKET_URI'] = 'gs://orange_maroc'\n",
    "\n",
    "REGION = os.environ['REGION']\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "BUCKET_URI = os.environ['BUCKET_URI']\n",
    "\n",
    "# The number of dimensions for the textembedding-gecko@003 is 768\n",
    "# If other embedder is used, the dimensions would probably need to change.\n",
    "DIMENSIONS = 768\n",
    "\n",
    "# Index Constants\n",
    "DISPLAY_NAME = \"orange_maroc\"\n",
    "DEPLOYED_INDEX_ID = \"orange_maroc_endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721034604.226915    8819 work_stealing_thread_pool.cc:321] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1721034604.725539    8819 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721034604.727733    8819 work_stealing_thread_pool.cc:321] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1721034604.936737    8819 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "vector_store = VertexAIVectorStore(project_id=PROJECT_ID, region=REGION, index_name=DISPLAY_NAME, index_endpoint_name=DEPLOYED_INDEX_ID, dimensions=DIMENSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector_store.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721034014.561751    8819 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721034015.017818   40257 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034015.021544    8819 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721034015.470022   40261 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034015.472271    8819 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721034015.477738    8819 work_stealing_thread_pool.cc:321] WorkStealingThreadPoolImpl::PrepareFork\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting datapoints MatchingEngineIndex index: projects/662868193247/locations/europe-west4/indexes/502362464684343296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721034017.798522   40539 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034017.876326    8819 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchingEngineIndex index Upserted datapoints. Resource name: projects/662868193247/locations/europe-west4/indexes/502362464684343296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721034018.514587   40544 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "\u001b[32mINFO:logger:Upserted data to the index.\u001b[0m\n",
      "I0000 00:00:1721034018.518419   40549 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "vector_store.upsert(texts, metadatas, embedding_model, datastore_client_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721034032.124761    8819 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721034032.510671   40547 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034032.511942    8819 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721034032.877357   40542 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034032.877904    8819 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721034032.880138    8819 work_stealing_thread_pool.cc:321] WorkStealingThreadPoolImpl::PrepareFork\n"
     ]
    }
   ],
   "source": [
    "retriever = vector_store.retrieve(embedding_model, datastore_client_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Documents with ids: ['831a2c58-244a-4810-88ab-9e8110f83304', 'e871d96d-57f4-4dd4-8bf6-49d6d56bae8b', 'f11f04d6-f8a5-4da5-bf92-83d0c302c7b9'] not found in the storage",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are my options in breathable fabric?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag_gcp/raggcp/lib/python3.9/site-packages/langchain_core/retrievers.py:222\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    221\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    225\u001b[0m         result,\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/rag_gcp/raggcp/lib/python3.9/site-packages/langchain_core/retrievers.py:215\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/Desktop/rag_gcp/raggcp/lib/python3.9/site-packages/langchain_core/vectorstores/base.py:1151\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[1;32m   1149\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1151\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1153\u001b[0m         docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1154\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[1;32m   1155\u001b[0m                 query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[1;32m   1156\u001b[0m             )\n\u001b[1;32m   1157\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/rag_gcp/raggcp/lib/python3.9/site-packages/langchain_google_vertexai/vectorstores/vectorstores.py:160\u001b[0m, in \u001b[0;36m_BaseVertexAIVectorStore.similarity_search\u001b[0;34m(self, query, k, filter, numeric_filter, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    134\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m        query: The string that will be used to search for similar documents.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m        A list of k matching documents.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    159\u001b[0m         document\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m document, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_filter\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     ]\n",
      "File \u001b[0;32m~/Desktop/rag_gcp/raggcp/lib/python3.9/site-packages/langchain_google_vertexai/vectorstores/vectorstores.py:81\u001b[0m, in \u001b[0;36m_BaseVertexAIVectorStore.similarity_search_with_score\u001b[0;34m(self, query, k, filter, numeric_filter)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query and their cosine distance from the query.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    query: String query look up documents similar to.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    Lower score represents more similarity.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m embbedings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embeddings\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_by_vector_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membbedings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_filter\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag_gcp/raggcp/lib/python3.9/site-packages/langchain_google_vertexai/vectorstores/vectorstores.py:130\u001b[0m, in \u001b[0;36m_BaseVertexAIVectorStore.similarity_search_by_vector_with_score\u001b[0;34m(self, embedding, k, filter, numeric_filter)\u001b[0m\n\u001b[1;32m    128\u001b[0m missing_docs \u001b[38;5;241m=\u001b[39m [key \u001b[38;5;28;01mfor\u001b[39;00m key, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, documents) \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    129\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocuments with ids: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_docs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in the storage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: Documents with ids: ['831a2c58-244a-4810-88ab-9e8110f83304', 'e871d96d-57f4-4dd4-8bf6-49d6d56bae8b', 'f11f04d6-f8a5-4da5-bf92-83d0c302c7b9'] not found in the storage"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721034272.966119   41133 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034272.968109   41133 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034277.964902   41133 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034282.967447   41133 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "retriever.invoke(\"What are my options in breathable fabric?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:logger:Index endpoint orange_maroc_endpoint  exists with resource name as projects/662868193247/locations/europe-west4/indexEndpoints/6559915069730193408 and endpoint domain name as 1823754328.europe-west4-662868193247.vdb.vertexai.goog\u001b[0m\n",
      "\u001b[32mINFO:logger:Undeploying index with id orange_maroc_endpoint from Index endpoint orange_maroc_endpoint\u001b[0m\n",
      "\u001b[32mINFO:logger:\u001b[0m\n",
      "\u001b[32mINFO:logger:Deleting Index endpoint orange_maroc_endpoint with id projects/662868193247/locations/europe-west4/indexEndpoints/6559915069730193408\u001b[0m\n",
      "\u001b[32mINFO:logger:Deleting Index orange_maroc with id projects/662868193247/locations/europe-west4/indexes/502362464684343296\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721034653.218987   49675 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034793.325641   49675 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034863.384886   49576 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1721034863.385607   49576 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "vector_store.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raggcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
